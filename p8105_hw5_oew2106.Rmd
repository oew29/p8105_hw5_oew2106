---
title: "Homework 5"
author: "Olivia Wagner"
date: "11/7/2019"
output: github_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(knitr)
```


## Problem 1 ##
```{r problem 1}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))


## function which replaces missing values ##

i = 1

replace_missing = function(x) {
  for(i in 1:length(x)){
    if(is.na(x[i]) == TRUE){
      if(is.numeric(x) == TRUE){
          x[i] = mean(x, na.rm = TRUE)
      }
      else if(is.character(x) == TRUE){
          x[i] = 'virginica'
      } 
    }
  }
  return(x)
}

## apply to iris_with_missing data set ##
output = map(iris_with_missing, replace_missing)
print(output)

```


## Problem 2 ##

```{r problem 2}
# read in data #
longitudinal_table = list.files(path = '.', pattern = '*.csv') %>%
  map_df(~read_csv(.))

# create data table #
longitudinal_table = longitudinal_table %>%
  mutate(subject = rep(1:10, length = n())) %>%
  mutate(arm = rep(1:2, each = 10)) %>%
  mutate(arm = ifelse(arm == 1, 'control', 'experimental'), time = as.character(arm)) %>% 
  select(subject, arm, week_1, week_2, week_3, week_4, week_5, week_6, week_7, week_8)%>%
  arrange(subject, arm) %>%
  pivot_longer(cols = starts_with('week_'), names_to = 'week', names_prefix = 'week_', values_to =   'measurement') %>%
  mutate(week = as.numeric(week)) 
 
# Make Plot #
ggplot(data = longitudinal_table, aes(x = week, y = measurement, group = interaction(arm, subject), color = factor(arm))) +
  geom_line() +
  geom_point() +
  ggtitle('Longitudinal Control and Experimental Data by Subject' )
  

```


## Problem 3 ##

```{r problem 3}

set.seed(1)

sim_regression = function(n, beta0 = 2, beta1) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 1, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, 50)
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta1_hat = coef(ls_fit)[2],
    p_value = coef(summary(ls_fit))[2,4]
  )
}

## Combine all of the B_1 estimates and p-values ##

beta_list = list("beta1_0" = 0,
              "beta1_1"  = 1, 
              "beta1_2"  = 2, 
              "beta1_3" = 3, 
              "beta1_4" = 4,
              "beta1_5"  = 5,
              "beta1_6"  = 6
              )
output = vector("list", length = 7)

for (i in 1:7) {
  output[[i]] = rerun(10000, sim_regression(n = 30, beta1 = beta_list[[i]])) %>% 
    bind_rows
}

# results table #

sim_results = tibble(beta_1 = c(0,1,2,3,4,5,6)) %>%
  mutate(output_lists = map(.x = beta_1, ~rerun(10000, sim_regression(n = 30, beta1 = .x))), estimate_df = map(output_lists, bind_rows)) %>%
  select(-output_lists) %>%
  unnest(estimate_df)

print(sim_results)


# plot 1 #

plot1_data = sim_results %>%
  mutate(tally = ifelse(p_value <= 0.05, 1, 0)) %>%
  group_by(beta_1) %>%
  summarize(total = n(), reject = sum(tally)) %>%
  mutate(prop = reject/total) %>%
  print()

ggplot(data = plot1_data, aes(x = beta_1, y = prop))+
  geom_point()+
  ggtitle('Proportion of Rejections by Beta_1 Value' )


# plot 2 #

plot2_data = sim_results %>% 
  group_by(beta_1) %>%
  summarise(beta1_average = mean(beta1_hat))

ggplot(data = plot2_data, aes(x = beta_1, y = beta1_average))+
      geom_point()+
      scale_y_continuous(limits = c(0,20))+
      ggtitle('True Beta 1 vs. the overall average Beta 1 Hat')


# Plot 3 #

plot3_data = sim_results%>%
  filter(p_value <= 0.05)%>%
  group_by(beta_1)%>%
  summarise(beta1_average = mean(beta1_hat))

ggplot(data = plot3_data, aes(x = beta_1, y = beta1_average))+
  geom_point()+
  ggtitle('True Beta 1 vs. average Beta 1 Hat for which the Null was Rejected')

```
The first plot shows that the larger the effect size or beta 1, the greater the power, on average. 

In the third plot, the sample average for which the null is rejected is not approximately equal to the true value of Beta 1. This is because in order for beta 1 to be considered signficiantly different from the null value, beta 1 hat must deviate from the true beta by enough such that its occurence is unlikely to be explained by natural variation within the population. Thus, any values close to that of the true beta 1 would not have a p value less than or equal to 0.05.
